# üìÑ Document Scanner & Summarizer

A powerful Python CLI tool that extracts text from various document sources (images, PDFs, web pages) and provides AI-powered analysis through interactive conversations with streaming responses.

## ‚ú® Features

### Document Extraction

- **Multi-format support**: Images (JPG, PNG, TIFF), PDFs, DOCX files, and web URLs
- **Dual OCR engines**:
  - Tesseract (free, local, great for printed text)
  - Mistral OCR (API-based, excellent for handwriting and complex layouts)
- **Smart preprocessing**: Automatic image enhancement for optimal OCR accuracy
- **PDF handling**: Text extraction with OCR fallback for scanned documents
- **Web scraping**: Intelligent article extraction from URLs

### AI-Powered Analysis

- **Multiple AI providers**:
  - Anthropic Claude (claude-sonnet-4-5-20250929)
  - OpenAI GPT (gpt-5.1-2025-11-13)
  - Google Gemini (gemini-3-pro-preview)
- **Streaming responses**: Real-time output as AI generates text
- **Interactive chat**: Natural conversation interface for document analysis
- **Context-aware**: Multiturn conversations with full conversation history
- **Multiple summary styles**: Concise, detailed, or bullet-point summaries

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/objones25/document-scanner-summarizer.git
cd document_scanner_summarizer

# Install dependencies with uv
uv sync

# Set up API keys
cp .env.example .env
# Edit .env and add your API keys (at least one AI provider required)
```

### Required API Keys

Add to your `.env` file:

```bash
# AI Analysis (choose at least one)
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...

# OCR (optional - only for Mistral OCR)
MISTRAL_API_KEY=...
```

## üíª Usage

### Interactive Mode (Recommended)

```bash
python main.py
```

The CLI will guide you through:

1. üìÑ Select document source (file path or URL)
2. üîç Choose OCR engine (Tesseract or Mistral)
3. ü§ñ Select AI provider (Anthropic, OpenAI, or Gemini)
4. üí¨ Start interactive conversation

### Command Line Mode

```bash
# Analyze a specific file
python main.py document.pdf

# Analyze a web page
python main.py https://example.com/article

# Analyze an image with Mistral OCR and Anthropic
python main.py workout_notes.jpg --ocr mistral --provider anthropic

# Get a quick summary and exit
python main.py document.pdf --summary-only

# Get detailed bullet-point summary
python main.py document.pdf --summary-only --summary-style bullet-points

# Use specific providers
python main.py document.pdf --provider openai
```

### Command Line Arguments

```text
positional arguments:
  source                Document source (file path or URL)

optional arguments:
  -h, --help           Show help message
  --ocr {tesseract,mistral}
                       OCR engine to use (default: tesseract)
  --provider {anthropic,openai,gemini}
                       AI provider for analysis (default: anthropic)
  --summary-only       Generate summary and exit (no interactive mode)
  --summary-style {concise,detailed,bullet-points}
                       Summary style (default: concise)
  --thinking           Enable extended reasoning mode (Gemini only)
  --grounding          Enable Google Search grounding (Gemini only)
  --code-execution     Enable code execution (Gemini and Claude)
  --web-search         Enable web search with citations (Claude only)
  --web-fetch          Enable web page/PDF fetching (Claude only)
```

### Claude Advanced Features

When using Anthropic Claude as your AI provider, you can enable powerful advanced features:

#### Code Execution (`--code-execution`)
Enables Claude to run Python code and bash commands in a secure sandbox:

```bash
python main.py data_report.pdf --provider anthropic --code-execution
```

Claude can analyze data, create visualizations, perform calculations, and manipulate files. The sandbox includes pre-installed libraries like pandas, numpy, matplotlib, and scikit-learn.

#### Web Search (`--web-search`)
Enables Claude to search the web with automatic citations:

```bash
python main.py article.pdf --provider anthropic --web-search
```

Claude autonomously searches when needed and includes citations directing readers to source material. Perfect for questions requiring current information beyond the document.

#### Web Fetch (`--web-fetch`)
Allows Claude to retrieve and analyze full content from web pages and PDFs:

```bash
python main.py document.pdf --provider anthropic --web-fetch
```

Claude can fetch addresses explicitly provided by users or derived from search results. Note: Does not support JavaScript-rendered sites.

#### Combining Features

You can enable multiple features simultaneously:

```bash
python main.py research.pdf --provider anthropic --code-execution --web-search --web-fetch
```

### Gemini Advanced Features

When using Google Gemini as your AI provider, you can enable powerful advanced features:

#### Extended Reasoning Mode (`--thinking`)
Enables deep thinking capabilities for complex analysis:

```bash
python main.py document.pdf --provider gemini --thinking
```

This mode makes Gemini think more deeply about the content, providing more thorough and well-reasoned responses.

#### Google Search Grounding (`--grounding`)
Allows Gemini to search the web for up-to-date information:

```bash
python main.py article.pdf --provider gemini --grounding
```

Use this when you need current information or want to verify facts against real-time web data.

#### Code Execution (`--code-execution`)
Enables Gemini to run Python code for data analysis:

```bash
python main.py data_report.pdf --provider gemini --code-execution
```

Perfect for documents containing data, statistics, or when you need computational analysis.

#### Combining Features

You can enable multiple features simultaneously:

```bash
python main.py research.pdf --provider gemini --thinking --grounding --code-execution
```

## üí¨ Interactive Commands

Once in interactive mode, you can use these commands:

### Ask Questions

Just type your question and press Enter:

```text
You: What are the main conclusions?
You: Can you explain the methodology in detail?
You: Who are the key people mentioned?
You: Could you list all the exercises in the workout?
```

### Get Summaries

Use the `/summary` command with optional style:

```text
You: /summary                    # Concise summary (2-4 paragraphs)
You: /summary detailed           # Comprehensive summary with sections
You: /summary bullet-points      # Structured bullet-point summary
```

### Manage Conversation

```text
You: /clear                      # Clear conversation history
You: /exit                       # Exit the program
```

**Tip**: Press `Ctrl+C` or `Ctrl+D` to exit anytime.

## üìñ Example Workflows

### Example 1: Analyze a Research Paper

```bash
python main.py research_paper.pdf --provider anthropic
```

Interactive session:

```text
You: /summary detailed
ü§ñ AI: This paper investigates...

You: What methodology did they use?
ü§ñ AI: The researchers employed a mixed-methods approach...

You: What were the main limitations?
ü§ñ AI: The study has three primary limitations...
```

### Example 2: OCR Handwritten Workout Notes

```bash
python main.py workout_notes.jpg --ocr mistral --provider anthropic
```

```text
You: Could you list all the exercises?
ü§ñ AI:
Warm-Up:
1. Uphill walk on treadmill...

Strength Set 1 (2 rounds):
1. Keiser high to low chops √ó 10...
[continues with full exercise list]
```

### Example 3: Quick Web Article Summary

```bash
python main.py https://example.com/tech-article --summary-only --summary-style bullet-points
```

Output:

```text
üìù Generating bullet-points summary...

- Main topic: New developments in AI reasoning systems
- Key points:
  ‚Ä¢ Breakthrough in multi-step reasoning capabilities
  ‚Ä¢ 40% improvement in complex problem-solving tasks
  ‚Ä¢ New training methodology using reinforcement learning
- Conclusion: Significant step toward more capable AI systems
```

### Example 4: Analyze Meeting Notes from DOCX

```bash
python main.py meeting_notes.docx --provider openai
```

```text
You: What action items were mentioned?
ü§ñ AI: Based on the meeting notes, here are the action items...

You: Who is responsible for the Q2 budget report?
ü§ñ AI: According to the notes, Sarah Johnson is responsible...
```

## üìÅ Supported File Types

| Category | Formats | Method |
|----------|---------|--------|
| **Images** | `.jpg`, `.jpeg`, `.png`, `.bmp`, `.tiff`, `.tif` | OCR (Tesseract or Mistral) |
| **Documents** | `.pdf` | Text extraction + OCR fallback |
| **Documents** | `.docx` | Direct text extraction |
| **Documents** | `.txt` | Direct text extraction (UTF-8/Latin-1) |
| **Web** | `http://`, `https://` | Web scraping + article parsing |

## üèóÔ∏è Project Structure

```text
document_scanner_summarizer/
‚îú‚îÄ‚îÄ main.py                    # CLI entry point
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                # Interactive CLI interface
‚îÇ   ‚îú‚îÄ‚îÄ extractors.py         # Universal text extraction
‚îÇ   ‚îú‚îÄ‚îÄ ocr.py                # OCR engines (Tesseract, Mistral)
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py      # Image preprocessing pipeline
‚îÇ   ‚îî‚îÄ‚îÄ summarizer.py         # AI conversation & analysis
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_ocr.py           # OCR unit tests
‚îÇ   ‚îú‚îÄ‚îÄ test_ocr_real_images.py # Integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_extractors.py   # Extraction tests
‚îÇ   ‚îî‚îÄ‚îÄ test_preprocessing.py # Preprocessing tests
‚îú‚îÄ‚îÄ pyproject.toml            # Project dependencies
‚îú‚îÄ‚îÄ .env.example              # Environment template
‚îî‚îÄ‚îÄ README.md                 # This file
```

## üß™ Testing

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_extractors.py

# Run with coverage
pytest --cov=src tests/

# Skip slow integration tests
pytest -m "not slow"
```

**Test coverage:**

- ‚úÖ 135+ tests across all modules
- ‚úÖ Unit tests with mocking
- ‚úÖ Integration tests with real OCR
- ‚úÖ Type checking with proper annotations

## üîß Advanced Usage

### Use as a Library

```python
from src.extractors import extract_text
from src.summarizer import create_summarizer

# Extract text
text = extract_text("document.pdf")

# Create summarizer
summarizer = create_summarizer(text, provider_name="anthropic")

# Get streaming summary
for chunk in summarizer.summarize(style="concise"):
    print(chunk, end="", flush=True)

# Ask questions
for chunk in summarizer.ask("What are the key findings?"):
    print(chunk, end="", flush=True)
```

### Custom System Prompts

```python
from src.summarizer import DocumentSummarizer, AnthropicProvider

provider = AnthropicProvider()
summarizer = DocumentSummarizer(
    provider=provider,
    document_text=text,
    system_prompt="You are a legal document analyst. Focus on contracts and terms."
)
```

### Custom Models

```python
from src.summarizer import create_summarizer

# Use a specific model version
summarizer = create_summarizer(
    document_text=text,
    provider_name="anthropic",
    model="claude-3-5-sonnet-20241022"  # Custom model
)
```

## üõ†Ô∏è Development

### Prerequisites

- Python 3.13+
- uv package manager
- Tesseract OCR (for local OCR)

### Setup Development Environment

```bash
# Clone repository
git clone https://github.com/objones25/document-scanner-summarizer.git
cd document_scanner_summarizer

# Install dependencies
uv sync

# Install Tesseract (macOS)
brew install tesseract

# Run tests
pytest

# Type checking
mypy src/
```

### Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## üìù License

MIT License - see LICENSE file for details

## üôè Acknowledgments

- Built with [Anthropic Claude](https://www.anthropic.com/)
- OCR powered by [Tesseract](https://github.com/tesseract-ocr/tesseract) and [Mistral AI](https://mistral.ai/)
- OpenAI and Google AI for additional LLM support
